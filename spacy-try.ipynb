{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPACY APPROACH FOR NLP CHATBOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- python -m spacy download en_core_web_sm\n",
    "  \n",
    "    This will download the english nlp pipeline package\n",
    "    It contains:\n",
    "    - tok2vec\n",
    "    - tagger\n",
    "    - parser\n",
    "    - senter\n",
    "    - attribute_ruler\n",
    "    - lemmatizer\n",
    "    - ner (Name Entity Recognition)\n",
    "        \n",
    "More Info: https://spacy.io/models/en#en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Dependencies\n",
    "# pip install spacy\n",
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "source_nlp = spacy.load(\"en_core_web_sm\")\n",
    "source_nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x17e4d3bdd60>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x17e4d3bddc0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x17e4d147e40>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x17e4d45aec0>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x17e4d44a200>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x17e4d147f20>)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If i want to create a new pipeline\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp.pipe_names\n",
    "\n",
    "# I can use components from other pipelines\n",
    "nlp.add_pipe(\"tok2vec\", source=source_nlp)\n",
    "nlp.add_pipe(\"senter\", source=source_nlp)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What  |  PRON  |  what\n",
      "is  |  AUX  |  be\n",
      "the  |  DET  |  the\n",
      "step  |  NOUN  |  step\n",
      "by  |  ADP  |  by\n",
      "step  |  NOUN  |  step\n",
      "procedure  |  NOUN  |  procedure\n",
      "for  |  ADP  |  for\n",
      "admission  |  NOUN  |  admission\n",
      "?  |  PUNCT  |  ?\n"
     ]
    }
   ],
   "source": [
    "doc = source_nlp(\"What is the step by step procedure for admission?\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.pos_, \" | \", token.lemma_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
